{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Selecting random texts"
      ],
      "metadata": {
        "id": "wWVs107hCfLo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_hAhrY_omVl",
        "outputId": "9a2f1b5c-2d63-4ec4-c06d-01646518e5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 random texts from January 2020 have been saved to /content/january_2020_sample.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both CSV files\n",
        "file_path_2021 = '/content/hatetoxic_2021.csv'\n",
        "df_2021 = pd.read_csv(file_path_2021)\n",
        "\n",
        "# Filter the dataframe for texts from January 2020\n",
        "january_2020_texts = df_2021.loc[(df_2021['year'] == 2020) & (df_2021['month'] == 1), 'text without punctuation and stopword']\n",
        "\n",
        "# Convert the filtered texts to a DataFrame\n",
        "january_2020_df = january_2020_texts.to_frame()\n",
        "\n",
        "# Randomly select 30 texts\n",
        "sampled_texts = january_2020_df.sample(n=30, random_state=42)  # `random_state` ensures reproducibility\n",
        "\n",
        "# Save the randomly selected texts to a new Excel sheet\n",
        "output_file_path = '/content/january_2020_sample.xlsx'\n",
        "sampled_texts.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"30 random texts from January 2020 have been saved to {output_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Threshold value optimisation"
      ],
      "metadata": {
        "id": "Y863cRx0CmVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_labels = [\n",
        "    \"inappropriate behaviour\",\n",
        "    \"covid-19 outbreak in singapore\",\n",
        "    \"singlish phrases\",\n",
        "    \"chinese-speaking foreigners in singapore\",\n",
        "    \"political polarization in singapore\",\n",
        "    \"online harassment\",\n",
        "    \"poor hygiene in public toilets\",\n",
        "    \"salary dissatisfaction\",\n",
        "    \"national service\",\n",
        "    \"mask enforcement\",\n",
        "    \"others\"\n",
        "]"
      ],
      "metadata": {
        "id": "J_m0vcy36uu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Initialize embedding model for similarity comparison\n",
        "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "\n",
        "# Generate embeddings for candidate and true labels\n",
        "candidate_label_embeddings = embedding_model.encode(candidate_labels)\n",
        "\n",
        "# Define similarity threshold for semantic match\n",
        "similarity_threshold = 0.3\n",
        "\n",
        "# Loop through each threshold and calculate F1-score based on semantic similarity\n",
        "for threshold in thresholds:\n",
        "    pred_labels = []\n",
        "    true_labels = df[\"True Label\"].tolist()\n",
        "\n",
        "    for text in df[\"text without punctuation and stopword\"]:\n",
        "        # Get classification scores\n",
        "        result = classifier(text, candidate_labels)\n",
        "\n",
        "        # Filter for scores above the threshold\n",
        "        top_predictions = [\n",
        "            candidate_labels[i]\n",
        "            for i, score in enumerate(result[\"scores\"]) if score >= threshold\n",
        "        ]\n",
        "\n",
        "        if top_predictions:\n",
        "            # Use the first top prediction if multiple predictions pass the threshold\n",
        "            predicted_label = top_predictions[0]\n",
        "        else:\n",
        "            predicted_label = \"others\"\n",
        "\n",
        "        pred_labels.append(predicted_label)\n",
        "\n",
        "    # Convert predicted and true labels to embeddings for semantic similarity\n",
        "    pred_embeddings = embedding_model.encode(pred_labels)\n",
        "    true_embeddings = embedding_model.encode(true_labels)\n",
        "\n",
        "    # Calculate cosine similarity for each prediction and true label pair\n",
        "    semantic_matches = [\n",
        "        1 if cosine_similarity([pred_embeddings[i]], [true_embeddings[i]])[0][0] >= similarity_threshold else 0\n",
        "        for i in range(len(pred_labels))\n",
        "    ]\n",
        "\n",
        "    # Calculate F1-score based on semantic matches\n",
        "    f1 = f1_score([1]*len(true_labels), semantic_matches)  # Compare all true positives in terms of semantic similarity\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\"Best threshold: {best_threshold}, Best F1-score: {best_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4CN9YYOLQGr",
        "outputId": "e4e710c5-fff0-4040-a2ce-eded098e0c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold: 0.1, Best F1-score: 0.2857\n"
          ]
        }
      ]
    }
  ]
}